name: Notebook Pages

# On schedule run the notebooks on a 'data-refresh' branch and generate pages
# then raise PR to merge changes to main.

# If src or notebooks are updated, run the notebooks to generate pages
# If project or execution time grows then change flow to 
# only run the notebooks that changed or if their associated data has changed.

# If pages changed, run 

on:
  schedule:
    # Runs every day after normal trading hours 9.30am - 4pm EST; 4pm = 9pm UTC = 8am AEST next day
    # entended hours 4am-8pm EST; 8pm = 1am UTC next day = 12pm AEST next day
    #- cron:  '0 1 * * 5' # extended hours every Thursday
    - cron:  '50 21 * * *' # normal hours every day

  # Have to run notebooks on main branch to refresh cache data
  push:
    branches:
      - main
    paths:
      - 'notebooks/**'

  pull_request:
    types: [opened, synchronize, reopened]
    paths:
      - 'notebooks/**'
      - 'src/*.py'
      - '!src/*_test.py'

  # Allows you to run this workflow manually from the Actions tab
  workflow_dispatch:
    # inputs:
      # dry-run:
      #   description: 'Dry Run'
      #   type: boolean
      #   required: false
      #   default: true

permissions:
  contents: write    

jobs:
  run-notebooks:
    runs-on: ubuntu-latest
    env: # timestamp matching for AU data files
      TZ: 'Australia/Sydney'      

    steps:
    - name: Checkout
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'
        cache: 'pip'
        cache-dependency-path: '**/requirements*.txt'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r src/requirements.txt 
        python -m ipykernel install --user --name python3
        jupyter kernelspec list
        ls -al ./data        
        cat data/hash.txt

    - name: Cache Data
      uses: actions/cache@v4
      with:
        path: data/**
        key: data-${{ hashFiles('data/hash.txt') }}
        restore-keys: data-

    - name: Run Standalone Notebooks
      # run standalone notebooks first (no hyphen in name), then ! *-and- notebooks, then *-and-* notebooks
      run: |
        ls -al ./data
        cat data/hash.txt        
        set -e
        find notebooks -name "*.ipynb" -not -name "*-*" -print0 | xargs -0 -I % -P $(nproc) jupyter nbconvert --config notebooks/nbconvert_cfg.py --to markdown %

    - name: Run Investment Notebooks
      # run notebooks with hyphen but exclude combo *-and-* notebooks
      run: |
        set -e
        find notebooks -name "*-*.ipynb" -not -name "*-and-*" -print0 | xargs -0 -I % -P $(nproc) jupyter nbconvert --config notebooks/nbconvert_cfg.py --to markdown %
          
    - name: Run Combo Notebooks
      # run combo *-and-* notebooks
      run: |
        set -e
        find notebooks -name "*-and-*.ipynb" -print0 | xargs -0 -I % -P $(nproc) jupyter nbconvert --config notebooks/nbconvert_cfg.py --to markdown %

    - name: Upload Pages
      uses: actions/upload-artifact@v4
      with:
        name: pages
        path: pages

    - name: Hash Data
      # Update hash of data files so we force new cache when data changes
      run: |
        ls -al ./data
        set -e
        find data -type f \( -name "*.csv" -o -name "*.md" \) | sort -n | xargs md5sum > data/hash.txt
        cat data/hash.txt

    - name: Commit changes
      if: github.ref != 'refs/heads/main'
      uses: stefanzweifel/git-auto-commit-action@v5
      with:
        branch: ${{ github.head_ref }}